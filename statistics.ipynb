{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_fidelity\n",
    "import torchvision\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN\n",
    "from torchvision.models.detection.backbone_utils import LastLevelMaxPool\n",
    "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from dataset import FeatureDataset\n",
    "import networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP (Approximation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_group(group: str, classification: list):\n",
    "    if group == \"Old&Asian\":\n",
    "        return classification[2] == \"Asian\" and classification[4] == \"70+\"\n",
    "    elif group == \"Young&Asian\":\n",
    "        return classification[2] == \"Asian\" and classification[4] == \"20-29\"\n",
    "    elif group == \"Old&non-Asian\":\n",
    "        return classification[2] != \"Asian\" and classification[4] == \"70+\"\n",
    "    elif group == \"Young&non-Asian\":\n",
    "        return classification[2] != \"Asian\" and classification[4] == \"20-29\"\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825\n",
      "0.6730769230769231\n",
      "0.6788461538461539\n",
      "0.8730769230769231\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"results/half+repetition/test_outputs.csv\"\n",
    "\n",
    "correct_predictions = [0,0,0,0]\n",
    "total_predictions = [0,0,0,0]\n",
    "with open(csv_file, 'r') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for row in csv_reader:\n",
    "        if re.search('Old&Asian', row[0]):\n",
    "            if check_group(\"Old&Asian\", row):\n",
    "                correct_predictions[0] += 1\n",
    "            total_predictions[0] += 1\n",
    "        elif re.search('Old&non-Asian', row[0]):\n",
    "            if check_group(\"Old&non-Asian\", row):\n",
    "                correct_predictions[1] += 1\n",
    "            total_predictions[1] += 1\n",
    "        elif re.search('Young&Asian', row[0]):\n",
    "            if check_group(\"Young&Asian\", row):\n",
    "                correct_predictions[2] += 1\n",
    "            total_predictions[2] += 1\n",
    "        elif re.search('Young&non-Asian', row[0]):\n",
    "            if check_group(\"Young&non-Asian\", row):\n",
    "                correct_predictions[3] += 1\n",
    "            total_predictions[3] += 1\n",
    "\n",
    "print(correct_predictions[0]/total_predictions[0])\n",
    "print(correct_predictions[1]/total_predictions[1])\n",
    "print(correct_predictions[2]/total_predictions[2])\n",
    "print(correct_predictions[3]/total_predictions[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Fidelity (Output Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colin\\AppData\\Local\\Temp\\ipykernel_7252\\1591604211.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_fair_4.load_state_dict(torch.load('FairFace/fair_face_models/res34_fair_align_multi_4_20190809.pt'))\n"
     ]
    }
   ],
   "source": [
    "model_fair_4 = torchvision.models.resnet34(pretrained=True)\n",
    "model_fair_4.fc = nn.Linear(model_fair_4.fc.in_features, 18)\n",
    "model_fair_4.load_state_dict(torch.load('FairFace/fair_face_models/res34_fair_align_multi_4_20190809.pt'))\n",
    "return_nodes = {\"avgpool\": \"avgpool\"}\n",
    "fair_4_features = create_feature_extractor(model_fair_4, return_nodes=return_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_paths = []\n",
    "for dir in Path('test').glob('**/*'):\n",
    "    true_paths.extend(dir.glob('*.png'))\n",
    "\n",
    "out_paths = []\n",
    "for dir in Path('results/all').glob('**/*'):\n",
    "    if dir.is_dir():\n",
    "        out_paths.extend(dir.glob('*.png'))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "true_features = FeatureDataset(true_paths, 224, fair_4_features, 'cuda', transform)\n",
    "out_features = FeatureDataset(out_paths, 224, fair_4_features, 'cuda', transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"test/Young&Asian\" with extensions png,jpg,jpeg\n",
      "Found 520 samples\n",
      "Processing samples                                                        \n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"results/all/Young&Asian\" with extensions png,jpg,jpeg\n",
      "Found 520 samples\n",
      "Processing samples                                                        \n",
      "Frechet Inception Distance: 114.53709028044153\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frechet_inception_distance': 114.53709028044153, 'kernel_inception_distance_mean': 0.09608116555630854, 'kernel_inception_distance_std': 1.6334298521730888e-07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kernel Inception Distance: 0.09608116555630854 Â± 1.6334298521730888e-07\n"
     ]
    }
   ],
   "source": [
    "metrics = torch_fidelity.calculate_metrics(\n",
    "    input1='test/Young&Asian',\n",
    "    input2='results/all/Young&Asian',\n",
    "    cuda=True,\n",
    "    fid=True,\n",
    "    kid=True,\n",
    "    kid_subset_size=520,\n",
    "    prc=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
